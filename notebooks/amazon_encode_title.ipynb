{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "import re\n",
    "import networkx\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from collections import Counter\n",
    "import itertools\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12500875it [02:30, 82862.26it/s] \n"
     ]
    }
   ],
   "source": [
    "fhr = open('../datasets/amazon-meta.txt', 'r', encoding='utf-8', errors='ignore')\n",
    "\n",
    "\n",
    "columns = ['Title', 'Categories', 'Group', 'SalesRank', 'TotalReviews', 'AvgRating']\n",
    "MetaData = dict(zip(columns, [[] for i in columns]))\n",
    "\n",
    "\n",
    "(Id, ASIN, Title, Categories, Group, Copurchased, SalesRank, TotalReviews, AvgRating, DegreeCentrality, ClusteringCoeff) = \\\n",
    "    (\"\", \"\", \"\", \"\", \"\", \"\", 0, 0, 0.0, 0, 0.0)\n",
    "for line in tqdm(fhr):\n",
    "    line = line.strip()\n",
    "    # a product block started\n",
    "    if(line.startswith(\"title\")):\n",
    "        Title = line[6:].strip()\n",
    "        Title = ' '.join(Title.split())\n",
    "    elif(line.startswith(\"group\")):\n",
    "        Group = line[6:].strip()\n",
    "    elif(line.startswith(\"salesrank\")):\n",
    "        SalesRank = line[10:].strip()\n",
    "    elif(line.startswith(\"categories\")):\n",
    "        ls = line.split()\n",
    "        Categories = ' '.join((fhr.readline()).lower() for i in range(int(ls[1].strip())))\n",
    "        Categories = re.compile('[%s]' % re.escape(string.digits+string.punctuation)).sub(' ', Categories)\n",
    "    elif(line.startswith(\"reviews\")):\n",
    "        ls = line.split()\n",
    "        TotalReviews = ls[2].strip()\n",
    "        AvgRating = ls[7].strip()\n",
    "    elif (line==\"\"):\n",
    "        try:\n",
    "            MetaData['Title'].append(Title)\n",
    "            MetaData['Categories'].append(' '.join(set(Categories.split())))\n",
    "            MetaData['Group'].append(Group)\n",
    "            MetaData['SalesRank'].append(int(SalesRank))\n",
    "            MetaData['TotalReviews'].append(int(TotalReviews))\n",
    "            MetaData['AvgRating'].append(float(AvgRating))\n",
    "        except NameError as err:\n",
    "            print(err)\n",
    "            continue\n",
    "        (Id, ASIN, Title, Categories, Group, Copurchased, SalesRank, TotalReviews, AvgRating, DegreeCentrality, ClusteringCoeff) = \\\n",
    "            (\"\", \"\", \"\", \"\", \"\", \"\", 0, 0, 0.0, 0, 0.0)\n",
    "fhr.close()\n",
    "titles = MetaData['Title']\n",
    "del MetaData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from pickle import load\n",
    "\n",
    "def read_matrix_pickle():\n",
    "    # 0:14 -- float64\n",
    "    # 0:02 -- float32\n",
    "    with open(\"../datasets/model.pickle\", \"rb\") as f:\n",
    "        mat = PCA(4).fit_transform(load(f))\n",
    "        words = [i.split('_')[0] for i in load(f)]\n",
    "        word_dict = dict(zip(words, range(len(words))))\n",
    "        del words\n",
    "    return mat, word_dict\n",
    "\n",
    "w2v, word_dict = read_matrix_pickle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 548553/548553 [04:19<00:00, 2110.58it/s]\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "# 3:28\n",
    "matrix = np.zeros((len(titles), 4))\n",
    "n_words_list = []\n",
    "for i, title in tqdm(enumerate(titles), total=len(titles)):\n",
    "    n_words = 0\n",
    "    for word in title.split():\n",
    "        word = porter_stemmer.stem(word)\n",
    "        if word in word_dict:\n",
    "            n_words += 1\n",
    "            matrix[i] += w2v[word_dict[word]]\n",
    "    if n_words > 0:\n",
    "        matrix[i] = matrix[i] / n_words\n",
    "    n_words_list.append(n_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "zero_ind = np.array([i == 0 for i in n_words_list])\n",
    "nonzero_sub = matrix[~zero_ind, :]\n",
    "matrix[zero_ind, :] = nonzero_sub.mean(axis=0) +\n",
    "                      np.random.randn(zero_ind.sum(), matrix.shape[1]) * nonzero_sub.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import dump\n",
    "dump(matrix, open(\"../tmp_files/title_submatrix\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 60622,\n",
       "         1: 125751,\n",
       "         2: 146761,\n",
       "         3: 96854,\n",
       "         4: 57037,\n",
       "         5: 30909,\n",
       "         6: 15767,\n",
       "         7: 7806,\n",
       "         8: 3652,\n",
       "         9: 1781,\n",
       "         10: 794,\n",
       "         11: 419,\n",
       "         12: 233,\n",
       "         13: 79,\n",
       "         14: 52,\n",
       "         15: 17,\n",
       "         16: 7,\n",
       "         17: 8,\n",
       "         20: 1,\n",
       "         23: 1,\n",
       "         26: 2})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter(n_words_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
